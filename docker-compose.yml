version: '3.8'

services:
  app:
    build: .
    restart: on-failure
    ports:
      - "8080:8080"
      - "5005:5005"
    depends_on:
      elasticsearch:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - SPRING_RABBITMQ_HOST=rabbitmq
      - ELASTICSEARCH_HOST=elasticsearch
      - RABBITMQ_USERNAME=admin
      - RABBITMQ_PASSWORD=root
      - SPRING_REDIS_HOST=redis
      - SPRING_REDIS_PORT=6379
      - EMBEDDER_URL=http://embedder:80

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 10s
      timeout: 5s
      retries: 5

  rabbitmq:
    image: rabbitmq:3.9.5-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: root
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:6.2-alpine
    restart: on-failure
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  embedder:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.1
    ports:
      - "8081:80"
    environment:
      MODEL_ID: sentence-transformers/all-MiniLM-L6-v2
    volumes:
      - embedder-model-cache:/root/.cache/huggingface

  qdrant:
    image: qdrant/qdrant
    ports:
      - "6333:6333"
      - "6334:6334"

volumes:
  embedder-model-cache:
